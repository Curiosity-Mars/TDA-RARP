# Required Libraries
import pandas as pd
import numpy as np
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from community import community_louvain
import matplotlib.pyplot as plt
from google.colab import files
from io import StringIO

# Upload CSV file (Google Colab)
print("Please upload your CSV file:")
uploaded = files.upload()

# Read uploaded CSV into DataFrame
for filename in uploaded.keys():
    data = pd.read_csv(StringIO(uploaded[filename].decode('utf-8')))

# Select columns containing "EPIC" or "QOL"
qol_columns = [col for col in data.columns if 'EPIC' in col or 'QOL' in col]

# Define patient ID column name
patient_id_col = '症例番号'  # Change to 'Patient_ID' if your file uses English

# Check if patient ID column exists
if patient_id_col not in data.columns:
    print(f"Error: Column '{patient_id_col}' not found in the dataset.")
else:
    try:
        # Set patient ID as index
        data.set_index(patient_id_col, inplace=True)

        # Extract and preprocess QOL data
        qol_data = data[qol_columns].apply(pd.to_numeric, errors='coerce')
        qol_data.fillna(qol_data.mean(), inplace=True)

        # Compute cosine similarity matrix
        similarity_matrix = cosine_similarity(qol_data)

        # Build similarity graph
        G = nx.Graph()
        for i, case_id in enumerate(qol_data.index):
            G.add_node(case_id)

        # Set similarity threshold
        threshold = 0.7  # Adjust as needed

        for i in range(len(qol_data)):
            for j in range(i + 1, len(qol_data)):
                if similarity_matrix[i, j] > threshold:
                    G.add_edge(qol_data.index[i], qol_data.index[j], weight=similarity_matrix[i, j])

        # Remove isolated nodes (no edges)
        isolated_nodes = list(nx.isolates(G))
        G.remove_nodes_from(isolated_nodes)

        # Louvain community detection
        partition = community_louvain.best_partition(G)
        nx.set_node_attributes(G, partition, "community")

        # Node sizes based on degree
        max_degree = max(dict(G.degree()).values())
        node_sizes = [300 + 300 * (G.degree(n) / max_degree) for n in G.nodes()]

        # Visualize the network
        pos = nx.spring_layout(G, seed=42)
        plt.figure(figsize=(14, 14))
        nx.draw_networkx_nodes(G, pos, node_size=node_sizes,
                               node_color=list(partition.values()),
                               cmap=plt.cm.Set1)
        nx.draw_networkx_edges(G, pos, alpha=0.2, edge_color='gray', width=1)
        plt.title("Patient Network with Central Clusters (Threshold = 0.7)")
        plt.axis("off")
        plt.show()

        # Create DataFrame with community assignments
        community_df = pd.DataFrame({
            patient_id_col: list(partition.keys()),
            'Community': list(partition.values())
        })

        # Save to CSV
        output_file = "qol_community_data_central.csv"
        community_df.to_csv(output_file, index=False)
        print(f"\nThe result has been saved to: {output_file}")

        # Trigger download in Colab
        files.download(output_file)

    except Exception as e:
        print(f"An error occurred during processing:\n{e}")

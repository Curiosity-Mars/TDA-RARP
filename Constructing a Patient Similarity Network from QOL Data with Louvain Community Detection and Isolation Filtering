# Required libraries
import pandas as pd
import numpy as np
import networkx as nx
from sklearn.metrics.pairwise import cosine_similarity
from community import community_louvain
import matplotlib.pyplot as plt
from google.colab import files
from io import StringIO

# Step 1: Upload CSV file in Google Colab
print("Please upload your CSV file:")
uploaded = files.upload()

# Step 2: Load CSV into a DataFrame
for filename in uploaded.keys():
    data = pd.read_csv(StringIO(uploaded[filename].decode('utf-8')))

# Step 3: Check for the required patient ID column
patient_id_col = '症例番号'  # Change to 'Patient_ID' if your dataset uses English
if patient_id_col not in data.columns:
    print(f"Error: Required column '{patient_id_col}' not found in the uploaded file.")
else:
    try:
        # Step 4: Set the patient ID as index
        data.set_index(patient_id_col, inplace=True)

        # Step 5: Select columns containing 'EPIC' or 'QOL'
        qol_columns = [col for col in data.columns if 'EPIC' in col or 'QOL' in col]
        qol_data = data[qol_columns]

        # Step 6: Convert to numeric and impute missing values with column means
        qol_data = qol_data.apply(pd.to_numeric, errors='coerce')
        qol_data.fillna(qol_data.mean(), inplace=True)

        # Step 7: Compute cosine similarity between patients
        similarity_matrix = cosine_similarity(qol_data)

        # Step 8: Build graph from similarity matrix
        G = nx.Graph()
        for i, patient in enumerate(qol_data.index):
            G.add_node(patient)

        similarity_threshold = 0.6  # You may adjust this value as needed
        for i in range(len(qol_data)):
            for j in range(i + 1, len(qol_data)):
                if similarity_matrix[i, j] > similarity_threshold:
                    G.add_edge(qol_data.index[i], qol_data.index[j],
                               weight=similarity_matrix[i, j])

        # Step 9: Remove isolated nodes
        isolated_nodes = list(nx.isolates(G))
        G.remove_nodes_from(isolated_nodes)

        # Step 10: Detect communities using Louvain algorithm
        partition = community_louvain.best_partition(G)
        nx.set_node_attributes(G, partition, "community")

        # Step 11: Define node sizes based on degree
        max_degree = max(dict(G.degree()).values()) if G.number_of_nodes() > 0 else 1
        node_sizes = [300 + 300 * (G.degree(n) / max_degree) for n in G.nodes()]

        # Step 12: Plot the graph
        pos = nx.spring_layout(G, seed=42)
        plt.figure(figsize=(14, 14))
        nx.draw_networkx_nodes(
            G, pos,
            node_size=node_sizes,
            node_color=list(partition.values()),
            cmap=plt.cm.Set1
        )
        nx.draw_networkx_edges(
            G, pos,
            alpha=0.2,
            edge_color='gray',
            width=1
        )
        plt.title("Patient Network (Nodes = Patients, Threshold = 0.6)")
        plt.axis("off")
        plt.show()

        # Step 13: Save community assignments to CSV
        community_df = pd.DataFrame({
            patient_id_col: list(partition.keys()),
            'Community': list(partition.values())
        })
        output_file = "qol_community_data_patients.csv"
        community_df.to_csv(output_file, index=False)
        print(f"\nCommunity assignment saved to: {output_file}")

        # Step 14: Trigger download (Colab)
        files.download(output_file)

    except Exception as e:
        print(f"An error occurred during processing:\n{e}")
